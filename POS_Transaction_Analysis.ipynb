{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T06:38:53.629405Z",
     "start_time": "2024-08-28T06:38:52.862223Z"
    }
   },
   "source": "from StoredQueries import POS_transactions",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:38:58.593004Z",
     "start_time": "2024-08-28T06:38:56.466028Z"
    }
   },
   "cell_type": "code",
   "source": "POS_df = POS_transactions()",
   "id": "9775574f51d29c17",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:38:58.623775Z",
     "start_time": "2024-08-28T06:38:58.593978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create list of all transactions grouped by each transaction\n",
    "POS_df.head()"
   ],
   "id": "5140ae836134906a",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:38:59.709845Z",
     "start_time": "2024-08-28T06:38:58.644374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grouping the data by 'TransactionID' and aggregating the 'PartName' into a list\n",
    "grouped_df = POS_df.groupby('TransactionID')['PartName'].apply(list).reset_index()\n",
    "\n",
    "# Renaming the columns\n",
    "grouped_df.columns = ['TransactionID', 'PartNames']\n",
    "\n"
   ],
   "id": "1fbaa5a89e33ec35",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:39:00.660054Z",
     "start_time": "2024-08-28T06:39:00.647314Z"
    }
   },
   "cell_type": "code",
   "source": "grouped_df.head(20)",
   "id": "efb07ac6951ab392",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:39:01.938187Z",
     "start_time": "2024-08-28T06:39:01.877938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sorting each list of part names and converting to a tuple\n",
    "grouped_df['SortedPartNames'] = grouped_df['PartNames'].apply(lambda x: tuple(sorted(x)))\n",
    "\n",
    "# Group by the sorted part names and count the occurrences\n",
    "count_df = grouped_df.groupby('SortedPartNames').size().reset_index(name='Count')\n",
    "\n",
    "# Renaming the columns for clarity\n",
    "count_df.columns = ['TransactionLists', 'Count']"
   ],
   "id": "f29311101a487863",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:39:03.309606Z",
     "start_time": "2024-08-28T06:39:03.291702Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_count_df = count_df[count_df['TransactionLists'].apply(lambda x: len(x) >= 2)]",
   "id": "e349cbb5a5b8a7af",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T06:39:03.826442Z",
     "start_time": "2024-08-28T06:39:03.804408Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_count_df.nlargest(500, 'Count').to_csv('POS_Transactions_Count.csv', index=False)",
   "id": "9d3a858249e9c54a",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This section performs the analysis of how often each item appears in a transaction with each other item.",
   "id": "1a1e851b472add3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "transactions = grouped_df[\"PartNames\"]\n",
    "unique_parts = set(part for sublist in transactions for part in sublist)\n",
    "\n",
    "combs = list(combinations(unique_parts, 2))\n",
    "\n",
    "comb_counts = {comb: 0 for comb in combs}\n",
    "\n",
    "for transaction in transactions:\n",
    "    for comb in combinations(transaction, 2):\n",
    "        if comb in comb_counts:\n",
    "            comb_counts[comb] += 1\n",
    "        elif (comb[1], comb[0]) in comb_counts:\n",
    "            comb_counts[(comb[1], comb[0])] += 1\n",
    "            \n",
    "comb_df = pd.DataFrame(list(comb_counts.items()), columns=['Combination', 'Count'])\n"
   ],
   "id": "66c9ce4b15ecf476",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comb_df['Count'] = comb_df['Count'].astype(int) # make sure these are integers, so they can be properly sorted\n",
    "comb_df = comb_df.sort_values(by=\"Count\", ascending=False).reset_index(drop=True)\n",
    "comb_df.to_csv('POS_Transactions_Combinations.csv', index=False)"
   ],
   "id": "a372acce2bc86ab8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the second data frame from the combination dataframe. Step 1: Search through all transactions and create a items sold dataframe of the form (PartName, Qty, TotalPrice). Step 2: Loop through the combo data frame and create copies of each combination as A/B and one as B/A. Step 3: Match counts of the items sold dataframe to the combo dataframe to produce a ratio for each A/B and B/A record.",
   "id": "465819a4e45f7a24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Search through all transactions and create a items sold dataframe of the form (PartName, Qty, TotalPrice).\n",
    "part_count_df = POS_transactions()\n",
    "part_count_df.head()"
   ],
   "id": "b171b331cc599c36",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 1: Initial setup\n",
    "part_count_df = part_count_df[[\"PartName\", \"Qty\", \"UnitPrice\"]]\n",
    "part_count_df['TotalPrice'] = (part_count_df['Qty'] * part_count_df['UnitPrice'])\n",
    "part_count_df['TotalPrice'] = part_count_df['TotalPrice'].astype(float).round(2)\n",
    "\n",
    "# Step 2: Count the number of times each PartName appears\n",
    "part_count_series = part_count_df['PartName'].value_counts().reset_index()\n",
    "\n",
    "# Rename the columns to make it clear\n",
    "part_count_series.columns = ['PartName', 'PartCount']\n",
    "\n",
    "# Step 3: Sum Part Quantity by PartName\n",
    "total_qty_series = part_count_df.groupby('PartName')['Qty'].sum().reset_index()\n",
    "total_qty_series.columns = ['PartName', 'TotalPartQuantity']\n",
    "\n",
    "# Step 4: Merge the TotalPartQuantity and PartCount back with the original part_count_df\n",
    "part_count_df = pd.merge(part_count_df, part_count_series, on='PartName', how='left')\n",
    "part_count_df = pd.merge(part_count_df, total_qty_series, on='PartName', how='left')"
   ],
   "id": "def9d72676f9a0af",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "part_count_df.head(10)",
   "id": "185b880b86ce194d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grouped_df = part_count_df.groupby('PartName').agg({'TotalPrice': 'sum'}).reset_index()\n",
    "\n",
    "# Add the PartCount feature that counts the number of times each item appears in a transaction\n",
    "grouped_df = pd.merge(grouped_df, part_count_series, on='PartName', how='left')\n",
    "\n",
    "# Add the TotalPartQuantity feature from part_count_df, which measures the total number of each item sold across all transactions.\n",
    "grouped_df = pd.merge(grouped_df, total_qty_series, on='PartName', how='left')"
   ],
   "id": "8051a3f4a1fd881f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "grouped_df.head()",
   "id": "570168db56cd8f96",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2: Loop through the combo data frame and create copies of each combination as A/B and one as B/A.\n",
    "def create_combination_pairs(row):\n",
    "    part1, part2 = row['Combination']\n",
    "    return pd.DataFrame({\n",
    "        'Part1': [part1, part2],\n",
    "        'Part2': [part2, part1],\n",
    "        'Count': [row['Count'], row['Count']]\n",
    "    })\n",
    "\n",
    "# Apply the function to each row and concatenate the results\n",
    "expanded_df = pd.concat(comb_df.apply(create_combination_pairs, axis=1).tolist()).reset_index(drop=True)\n"
   ],
   "id": "86c4b462d1fd290a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "expanded_df.head()",
   "id": "8bd7f215c4682539",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 3: Match counts of the items sold dataframe to the combo dataframe to produce a ratio for each A/B and B/A record.\n",
    "# First merge on Part1\n",
    "merged_df_part1 = pd.merge(expanded_df, grouped_df, left_on='Part1', right_on='PartName', how='left')\n",
    "merged_df_part1 = merged_df_part1.rename(columns={'Qty': 'Qty_Part1', 'TotalPrice': 'TotalPrice_Part1'})\n",
    "\n",
    "# Second merge on Part2\n",
    "final_merged_df = pd.merge(merged_df_part1, grouped_df, left_on='Part2', right_on='PartName', how='left')\n",
    "final_merged_df = final_merged_df.rename(columns={'Qty': 'Qty_Part2', 'TotalPrice': 'TotalPrice_Part2'})\n",
    "\n",
    "# Remove extra columns\n",
    "final_merged_df = final_merged_df.drop(columns=['PartName_x', 'PartName_y'], axis='columns')\n",
    "\n",
    "# Include part ratio\n",
    "final_merged_df['PartSaleRatio'] = (final_merged_df['Count'] / final_merged_df['PartCount_x']).round(2)\n",
    "\n",
    "# Include Average part price\n",
    "final_merged_df['TotalPrice_Part1'] = pd.to_numeric(final_merged_df['TotalPrice_Part1'], errors='coerce')\n",
    "final_merged_df['PartCount_x'] = pd.to_numeric(final_merged_df['PartCount_x'], errors='coerce')\n",
    "final_merged_df['Part1_Average_Price'] = (final_merged_df['TotalPrice_Part1'] / final_merged_df['PartCount_x']).round(2)\n",
    "\n",
    "# Display Head\n",
    "final_merged_df.head(25)\n"
   ],
   "id": "baadce94d53a4230",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_merged_df.to_csv('POS_Transactions_Analysis.csv', index=False)",
   "id": "f7d5dec643166e5a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 1: Loop through the POS_transactions() query dataframe and create a dataframe of the form (Part1, Part2, Part1_Qty, Part2_Qty, PartRatio, Part1AvgPrice, Part2AvgPrice, AddedValue) Where Part1_Qty and Part2_Qty are the sum amount of each that appear in transactions together with the other, PartRatio = Part2 / Part1 when sold in the same transaction on average, Part1AvgPrice and Part2AvgPrice are the averages of each part in total sales, and AddedValue = PartRatio * Part2AvgPrice",
   "id": "93f2048a796b85a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 2: Send to CSV",
   "id": "12923e083c27d827"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step 3: Create Complete Added Value CSV, which includes each Part and its base value + the AddedValue from ALL of its other combinations.",
   "id": "f7bc20295ec6c881"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T05:16:07.793851Z",
     "start_time": "2024-08-29T05:16:05.890392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from StoredQueries import POS_transactions\n",
    "\n",
    "pos_df = POS_transactions()\n",
    "pos_df.head()"
   ],
   "id": "99f3ce31dfc30bba",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T05:33:12.282058Z",
     "start_time": "2024-08-29T05:27:34.188177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Step 1: Create the dataframe with combinations and calculations using PartName\n",
    "def create_part_combinations_df(pos_df):\n",
    "    part_combinations = []\n",
    "\n",
    "    # Loop through each transaction\n",
    "    for _, transaction in pos_df.groupby('TransactionID'):\n",
    "        # Get all possible 2-part combinations\n",
    "        for (part1, part2) in combinations(transaction['PartName'], 2):\n",
    "            part1_data = transaction[transaction['PartName'] == part1]\n",
    "            part2_data = transaction[transaction['PartName'] == part2]\n",
    "\n",
    "            part1_qty = part1_data['Qty'].sum()\n",
    "            part2_qty = part2_data['Qty'].sum()\n",
    "            part_ratio = part2_qty / part1_qty if part1_qty != 0 else 0\n",
    "            part1_avg_price = part1_data['UnitPrice'].mean()\n",
    "            part2_avg_price = part2_data['UnitPrice'].mean()\n",
    "            added_value = part_ratio * part2_avg_price\n",
    "\n",
    "            part_combinations.append({\n",
    "                'Part1': part1,\n",
    "                'Part2': part2,\n",
    "                'Part1_Qty': part1_qty,\n",
    "                'Part2_Qty': part2_qty,\n",
    "                'PartRatio': part_ratio,\n",
    "                'Part1AvgPrice': part1_avg_price,\n",
    "                'Part2AvgPrice': part2_avg_price,\n",
    "                'AddedValue': added_value\n",
    "            })\n",
    "\n",
    "    part_combinations_df = pd.DataFrame(part_combinations)\n",
    "    return part_combinations_df\n",
    "\n",
    "# Create the combinations dataframe using PartName\n",
    "part_combinations_df = create_part_combinations_df(pos_df)\n",
    "\n",
    "# Step 2: Save to CSV\n",
    "part_combinations_df.to_csv('part_combinations.csv', index=False)\n",
    "\n",
    "# Step 3: Create Complete Added Value CSV using PartName\n",
    "def create_complete_added_value_df(part_combinations_df):\n",
    "    complete_added_value = []\n",
    "\n",
    "    # Loop through each unique Part1 in the combinations dataframe\n",
    "    for part in part_combinations_df['Part1'].unique():\n",
    "        part_base_value = part_combinations_df[part_combinations_df['Part1'] == part]['Part1AvgPrice'].mean()\n",
    "        added_value_sum = part_combinations_df[part_combinations_df['Part1'] == part]['AddedValue'].sum()\n",
    "        total_value = part_base_value + added_value_sum\n",
    "\n",
    "        complete_added_value.append({\n",
    "            'Part': part,\n",
    "            'BaseValue': part_base_value,\n",
    "            'TotalAddedValue': added_value_sum,\n",
    "            'CompleteValue': total_value\n",
    "        })\n",
    "\n",
    "    complete_added_value_df = pd.DataFrame(complete_added_value)\n",
    "    return complete_added_value_df\n",
    "\n",
    "# Create the complete added value dataframe using PartName\n",
    "complete_added_value_df = create_complete_added_value_df(part_combinations_df)\n",
    "\n",
    "# Save the complete added value dataframe to CSV\n",
    "complete_added_value_df.to_csv('complete_added_value.csv', index=False)\n"
   ],
   "id": "e8743b257a9b18dc",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-29T06:45:21.932612Z",
     "start_time": "2024-08-29T06:40:35.076677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from StoredQueries import POS_transactions\n",
    "\n",
    "pos_df = POS_transactions()\n",
    "pos_df.head()\n",
    "\n",
    "# Step 1: Create the dataframe with combinations and calculations using PartName\n",
    "def create_part_combinations_df(pos_df):\n",
    "    part_combination_sums = {}\n",
    "\n",
    "    # Loop through each transaction\n",
    "    for _, transaction in pos_df.groupby('TransactionID'):\n",
    "        # Get all possible 2-part combinations\n",
    "        for (part1, part2) in combinations(transaction['PartName'], 2):\n",
    "            # Sort the parts to ensure consistent ordering (e.g., A-B and B-A are treated the same)\n",
    "            sorted_parts = tuple(sorted([part1, part2]))\n",
    "            \n",
    "            # Sum the quantities of each part in the current transaction\n",
    "            part1_qty = transaction[transaction['PartName'] == sorted_parts[0]]['Qty'].sum()\n",
    "            part2_qty = transaction[transaction['PartName'] == sorted_parts[1]]['Qty'].sum()\n",
    "\n",
    "            # Accumulate the quantities in the dictionary\n",
    "            if sorted_parts in part_combination_sums:\n",
    "                part_combination_sums[sorted_parts]['Part1_Qty'] += part1_qty\n",
    "                part_combination_sums[sorted_parts]['Part2_Qty'] += part2_qty\n",
    "            else:\n",
    "                part_combination_sums[sorted_parts] = {\n",
    "                    'Part1_Qty': part1_qty,\n",
    "                    'Part2_Qty': part2_qty\n",
    "                }\n",
    "\n",
    "    part_combinations = []\n",
    "    # Loop through the accumulated quantities and perform calculations\n",
    "    for (part1, part2), qtys in part_combination_sums.items():\n",
    "        part1_data = pos_df[pos_df['PartName'] == part1]\n",
    "        part2_data = pos_df[pos_df['PartName'] == part2]\n",
    "\n",
    "        part_ratio = qtys['Part2_Qty'] / qtys['Part1_Qty'] if qtys['Part1_Qty'] != 0 else 0\n",
    "        part1_avg_price = part1_data['UnitPrice'].mean()\n",
    "        part2_avg_price = part2_data['UnitPrice'].mean()\n",
    "        added_value = part_ratio * part2_avg_price\n",
    "\n",
    "        part_combinations.append({\n",
    "            'Part1': part1,\n",
    "            'Part2': part2,\n",
    "            'Part1_Qty': qtys['Part1_Qty'],\n",
    "            'Part2_Qty': qtys['Part2_Qty'],\n",
    "            'PartRatio': part_ratio,\n",
    "            'Part1AvgPrice': part1_avg_price,\n",
    "            'Part2AvgPrice': part2_avg_price,\n",
    "            'AddedValue': added_value\n",
    "        })\n",
    "\n",
    "    part_combinations_df = pd.DataFrame(part_combinations)\n",
    "    return part_combinations_df\n",
    "\n",
    "# Create the combinations dataframe using PartName\n",
    "part_combinations_df = create_part_combinations_df(pos_df)\n",
    "\n",
    "# Step 2: Save to CSV\n",
    "part_combinations_df.to_csv('part_combinations.csv', index=False)\n"
   ],
   "id": "b91ff121d2bc7f57",
   "execution_count": 1,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
