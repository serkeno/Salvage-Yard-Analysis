{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T07:03:02.349667Z",
     "start_time": "2024-07-23T07:03:02.294912Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import DataframeBuilder"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:03:02.364811Z",
     "start_time": "2024-07-23T07:03:02.352679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_type = \"TotalPrice\"\n",
    "presence_type = \"binary\""
   ],
   "id": "fbd41d0f2511fe3d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:03:42.113718Z",
     "start_time": "2024-07-23T07:03:02.366326Z"
    }
   },
   "cell_type": "code",
   "source": "vehicle_presence_df = DataframeBuilder.vehicle_presence(presence_type=presence_type, vehicle_type=\"year_model\", target_type=target_type)\n",
   "id": "8285af8f27f3271b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:03:42.129197Z",
     "start_time": "2024-07-23T07:03:42.114730Z"
    }
   },
   "cell_type": "code",
   "source": "vehicle_presence_df.columns = vehicle_presence_df.columns.astype(str)",
   "id": "964fd3a5f8b60b52",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:03:42.268008Z",
     "start_time": "2024-07-23T07:03:42.130221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the machine learning model steps here, including training and testing LR\n",
    "# Separating features and target\n",
    "X = vehicle_presence_df.drop(columns=[target_type, 'Date'])\n",
    "y = vehicle_presence_df[target_type]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ],
   "id": "cb5405f3d989a526",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:12:07.251668Z",
     "start_time": "2024-07-23T07:03:42.269005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Lasso regression model\n",
    "random_forest = RandomForestRegressor()\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for tuning\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_percentage_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame({\n",
    "    'n_estimators': results['param_n_estimators'],\n",
    "    'max_depth': results['param_max_depth'],\n",
    "    'max_features': results['param_max_features'],\n",
    "    'min_samples_split': results['param_min_samples_split'],\n",
    "    'min_samples_leaf': results['param_min_samples_leaf'],\n",
    "    'mean_test_score': results['mean_test_score'],\n",
    "    'std_test_score': results['std_test_score']\n",
    "})\n",
    "\n",
    "print(results_df)"
   ],
   "id": "b1e83c6abf3f0339",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n_estimators max_depth max_features  min_samples_split  min_samples_leaf  \\\n",
      "0             100      None         auto                  2                 1   \n",
      "1             200      None         auto                  2                 1   \n",
      "2             300      None         auto                  2                 1   \n",
      "3             100      None         auto                  5                 1   \n",
      "4             200      None         auto                  5                 1   \n",
      "..            ...       ...          ...                ...               ...   \n",
      "319           200        30         log2                  5                 4   \n",
      "320           300        30         log2                  5                 4   \n",
      "321           100        30         log2                 10                 4   \n",
      "322           200        30         log2                 10                 4   \n",
      "323           300        30         log2                 10                 4   \n",
      "\n",
      "     mean_test_score  std_test_score  \n",
      "0                NaN             NaN  \n",
      "1                NaN             NaN  \n",
      "2                NaN             NaN  \n",
      "3                NaN             NaN  \n",
      "4                NaN             NaN  \n",
      "..               ...             ...  \n",
      "319        -0.418680        0.121608  \n",
      "320        -0.418846        0.122192  \n",
      "321        -0.419994        0.121808  \n",
      "322        -0.418593        0.122135  \n",
      "323        -0.415541        0.120959  \n",
      "\n",
      "[324 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.44819198 -0.44722811 -0.44676426\n",
      " -0.43405324 -0.43531199 -0.43512099 -0.42959662 -0.42685502 -0.42455565\n",
      " -0.42287388 -0.42716596 -0.42739579 -0.42925553 -0.42316289 -0.42561159\n",
      " -0.41724595 -0.41930644 -0.42192547 -0.41850637 -0.41641575 -0.41716743\n",
      " -0.41499195 -0.41736311 -0.41733274 -0.41477556 -0.41736784 -0.41664756\n",
      " -0.44545082 -0.44659832 -0.44789686 -0.42570167 -0.42568342 -0.42341835\n",
      " -0.42261934 -0.41779417 -0.41959162 -0.41992065 -0.41758987 -0.41818041\n",
      " -0.41650204 -0.4158768  -0.41726057 -0.42047563 -0.41674374 -0.41797888\n",
      " -0.41588498 -0.41670128 -0.41690453 -0.41395026 -0.41532097 -0.41688593\n",
      " -0.41684047 -0.4167203  -0.4162579          nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.44329769 -0.4384974  -0.43871946 -0.43080836 -0.42985575 -0.42906037\n",
      " -0.4246265  -0.42432536 -0.42534636 -0.42772032 -0.42661297 -0.42445048\n",
      " -0.42594447 -0.42110745 -0.42582984 -0.41813728 -0.4207582  -0.41823757\n",
      " -0.4165216  -0.41693849 -0.41613203 -0.41745069 -0.41599965 -0.41518739\n",
      " -0.41987828 -0.41583729 -0.41579078 -0.4298192  -0.43441729 -0.42884856\n",
      " -0.41594149 -0.42149791 -0.42031321 -0.41843115 -0.41695355 -0.41791808\n",
      " -0.41895748 -0.41912011 -0.41539769 -0.42050292 -0.41732295 -0.41672621\n",
      " -0.41685369 -0.41854043 -0.41551793 -0.41784578 -0.41720071 -0.41719239\n",
      " -0.4140543  -0.41796309 -0.41653531 -0.41950058 -0.41803933 -0.41687791\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.45104758 -0.4478325  -0.44778761\n",
      " -0.43228618 -0.43524233 -0.43402691 -0.42523624 -0.42665382 -0.42497551\n",
      " -0.42719236 -0.42455471 -0.42669298 -0.42692017 -0.42432094 -0.42497454\n",
      " -0.42036773 -0.41755162 -0.41809925 -0.41803125 -0.41567685 -0.41820079\n",
      " -0.41777396 -0.41640415 -0.41823789 -0.42054597 -0.41921201 -0.41639117\n",
      " -0.44790888 -0.44796589 -0.44622987 -0.42282153 -0.4253286  -0.42167751\n",
      " -0.41719184 -0.42077572 -0.42109095 -0.41749513 -0.41705596 -0.42002635\n",
      " -0.41526308 -0.41674515 -0.4178265  -0.41528146 -0.41712726 -0.41678819\n",
      " -0.41274163 -0.41722491 -0.41736919 -0.41811917 -0.416988   -0.41726392\n",
      " -0.41781868 -0.41739409 -0.41882855         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.44990769 -0.44983097 -0.44730452 -0.4374384  -0.43457258 -0.4333041\n",
      " -0.42724113 -0.42788922 -0.4250346  -0.42676528 -0.42409364 -0.43048105\n",
      " -0.42749857 -0.42555753 -0.42739782 -0.42198153 -0.42320892 -0.41771613\n",
      " -0.42012886 -0.41930777 -0.41826134 -0.41618207 -0.41672673 -0.41787827\n",
      " -0.41673495 -0.42081545 -0.41751716 -0.4527196  -0.44930537 -0.44782198\n",
      " -0.42175306 -0.42701415 -0.42357439 -0.41854219 -0.41845985 -0.41725637\n",
      " -0.41817427 -0.41929053 -0.41848932 -0.41652277 -0.41909949 -0.41660533\n",
      " -0.41535542 -0.41696334 -0.41774304 -0.41913076 -0.41588571 -0.41499412\n",
      " -0.41860678 -0.41867983 -0.41884602 -0.41999434 -0.41859253 -0.41554102]\n",
      "  warnings.warn(\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.16142551 -0.16098171 -0.16353075\n",
      " -0.26274751 -0.26274162 -0.26346096 -0.31215986 -0.31063467 -0.3103577\n",
      " -0.29370355 -0.29198828 -0.29109299 -0.29950527 -0.29739553 -0.297659\n",
      " -0.32457947 -0.3249994  -0.32542102 -0.33998486 -0.33821633 -0.33899159\n",
      " -0.33857316 -0.33926492 -0.33885125 -0.34135213 -0.34338034 -0.34229817\n",
      " -0.16405045 -0.16688573 -0.16366658 -0.30765087 -0.30546303 -0.30750615\n",
      " -0.34839112 -0.35145336 -0.35027012 -0.33711928 -0.33619246 -0.33632631\n",
      " -0.33923002 -0.34011039 -0.33977513 -0.36061115 -0.35887763 -0.3604552\n",
      " -0.37129488 -0.37188222 -0.37103247 -0.37176911 -0.37100266 -0.37144428\n",
      " -0.37337779 -0.37379228 -0.37391092         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.2354514  -0.23312702 -0.23285623 -0.28284212 -0.28671418 -0.28500109\n",
      " -0.32022204 -0.31785206 -0.31999564 -0.30384429 -0.30220998 -0.30538671\n",
      " -0.31082339 -0.30867937 -0.30775133 -0.33063101 -0.33033002 -0.33042705\n",
      " -0.34303518 -0.3408569  -0.34025393 -0.34073033 -0.34145821 -0.34081539\n",
      " -0.34607628 -0.34386249 -0.34458399 -0.26294886 -0.26302659 -0.26679413\n",
      " -0.3303418  -0.32974784 -0.33093256 -0.35933377 -0.35819532 -0.35670514\n",
      " -0.34864058 -0.34825004 -0.34816317 -0.35159848 -0.35109322 -0.3502517\n",
      " -0.36533553 -0.3642283  -0.36465208 -0.37394288 -0.37424995 -0.37374515\n",
      " -0.37566514 -0.37536582 -0.37424373 -0.3757861  -0.37600228 -0.37556013\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.16908718 -0.1654044  -0.16475339\n",
      " -0.26255086 -0.2637357  -0.26442717 -0.30998599 -0.31036036 -0.31011123\n",
      " -0.29275222 -0.29100622 -0.29057646 -0.29650974 -0.29768229 -0.29754108\n",
      " -0.32646317 -0.32539218 -0.32441199 -0.33980695 -0.33844946 -0.33835421\n",
      " -0.33889106 -0.33919027 -0.3382854  -0.34282705 -0.34302578 -0.34186672\n",
      " -0.16495224 -0.16799958 -0.1657656  -0.30961118 -0.30798368 -0.30685322\n",
      " -0.35040543 -0.35020333 -0.35031935 -0.33698554 -0.33751933 -0.33687165\n",
      " -0.34131407 -0.3410196  -0.34019601 -0.3596704  -0.36035209 -0.35851933\n",
      " -0.37227379 -0.37082845 -0.372107   -0.3717141  -0.37089829 -0.37173912\n",
      " -0.37283174 -0.37290071 -0.37375589         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.16487298 -0.16725241 -0.16535012 -0.26320764 -0.26465795 -0.26390041\n",
      " -0.30987531 -0.31011602 -0.31043756 -0.28907406 -0.29195454 -0.29189535\n",
      " -0.29724333 -0.29542297 -0.29725882 -0.32545864 -0.32644057 -0.32574385\n",
      " -0.33896858 -0.33962869 -0.33888776 -0.33950085 -0.33826947 -0.3384155\n",
      " -0.34327695 -0.34236843 -0.34230002 -0.16219682 -0.1647761  -0.16303853\n",
      " -0.30594093 -0.30875501 -0.3064521  -0.34938169 -0.35084382 -0.35045316\n",
      " -0.33680733 -0.33590997 -0.33556733 -0.34048195 -0.34023685 -0.34038498\n",
      " -0.35931092 -0.35947237 -0.35926649 -0.37226662 -0.37119767 -0.37170376\n",
      " -0.37230979 -0.3713506  -0.37181042 -0.37450068 -0.37364441 -0.37232987]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:21:20.478034Z",
     "start_time": "2024-07-23T07:12:07.252683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_type = \"TotalPrice\"\n",
    "presence_type = \"continuous\"\n",
    "vehicle_presence_df = DataframeBuilder.vehicle_presence(presence_type=presence_type, vehicle_type=\"year_model\",\n",
    "                                                        target_type=target_type)\n",
    "\n",
    "vehicle_presence_df.columns = vehicle_presence_df.columns.astype(str)\n",
    "# Create the machine learning model steps here, including training and testing LR\n",
    "# Separating features and target\n",
    "X = vehicle_presence_df.drop(columns=[target_type, 'Date'])\n",
    "y = vehicle_presence_df[target_type]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Lasso regression model\n",
    "random_forest = RandomForestRegressor()\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for tuning\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5,\n",
    "                           scoring='neg_mean_absolute_percentage_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame({\n",
    "    'n_estimators': results['param_n_estimators'],\n",
    "    'max_depth': results['param_max_depth'],\n",
    "    'max_features': results['param_max_features'],\n",
    "    'min_samples_split': results['param_min_samples_split'],\n",
    "    'min_samples_leaf': results['param_min_samples_leaf'],\n",
    "    'mean_test_score': results['mean_test_score'],\n",
    "    'std_test_score': results['std_test_score']\n",
    "})\n",
    "\n",
    "print(results_df)"
   ],
   "id": "c6db56ddc65b0108",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.43840575 -0.43787163 -0.43869055\n",
      " -0.43235402 -0.43395299 -0.43251685 -0.42431547 -0.42313371 -0.42306431\n",
      " -0.42717025 -0.42912588 -0.42998159 -0.42863861 -0.42670254 -0.42661465\n",
      " -0.42668113 -0.42096504 -0.42067338 -0.41807799 -0.4182507  -0.41822574\n",
      " -0.41884577 -0.41847601 -0.41944549 -0.42383811 -0.4196622  -0.42011861\n",
      " -0.44385301 -0.44002702 -0.44197259 -0.43121054 -0.42819856 -0.42598521\n",
      " -0.42114801 -0.41928546 -0.41978427 -0.42062366 -0.42068325 -0.42065295\n",
      " -0.42204164 -0.41851141 -0.41883517 -0.42007702 -0.4194973  -0.41702209\n",
      " -0.4168312  -0.41599517 -0.41787051 -0.41787049 -0.41674783 -0.41659925\n",
      " -0.41790981 -0.41542758 -0.41809228         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.4345957  -0.42935177 -0.43502357 -0.42654031 -0.42621671 -0.4273325\n",
      " -0.42668269 -0.42044727 -0.42473808 -0.42628847 -0.42398068 -0.42537059\n",
      " -0.4253061  -0.42638761 -0.42361081 -0.41929984 -0.42016793 -0.42021798\n",
      " -0.42123237 -0.42065404 -0.41941655 -0.41717872 -0.41991515 -0.41903986\n",
      " -0.41906252 -0.41597052 -0.41769944 -0.43066112 -0.42928275 -0.42555797\n",
      " -0.42222273 -0.42413481 -0.42347606 -0.41895781 -0.419069   -0.42068099\n",
      " -0.41964675 -0.41852885 -0.41825467 -0.41706205 -0.41756487 -0.41729311\n",
      " -0.41879871 -0.41583787 -0.41638042 -0.41635714 -0.41680261 -0.41669356\n",
      " -0.41610274 -0.41704566 -0.41742595 -0.41648401 -0.41665912 -0.41489294\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.43949598 -0.43927306 -0.43779088\n",
      " -0.42913883 -0.4321466  -0.42891111 -0.4298969  -0.42291515 -0.42809634\n",
      " -0.43589586 -0.42944934 -0.42805735 -0.42845826 -0.42806563 -0.42613231\n",
      " -0.41778266 -0.42160971 -0.42389048 -0.41659822 -0.41849605 -0.41968821\n",
      " -0.42291548 -0.42037014 -0.4181344  -0.4183039  -0.42061183 -0.41846058\n",
      " -0.4420662  -0.44422707 -0.43999202 -0.42496477 -0.425072   -0.4255267\n",
      " -0.4190741  -0.41973432 -0.41737098 -0.42025875 -0.41995557 -0.41929039\n",
      " -0.41774523 -0.42020454 -0.41894833 -0.41878007 -0.4190283  -0.41648871\n",
      " -0.41823539 -0.41675437 -0.42031039 -0.4207094  -0.41734088 -0.41884544\n",
      " -0.41915974 -0.41739086 -0.41757078         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.43184009 -0.43910038 -0.43667678 -0.43353054 -0.43297072 -0.43228009\n",
      " -0.4252655  -0.42289098 -0.42394393 -0.43531261 -0.4291976  -0.42896834\n",
      " -0.4272213  -0.42657684 -0.42470751 -0.42200777 -0.42296964 -0.42349618\n",
      " -0.42015463 -0.41929951 -0.42140818 -0.41989291 -0.42206075 -0.4195595\n",
      " -0.42193397 -0.42035433 -0.41701313 -0.43524334 -0.44261747 -0.4405496\n",
      " -0.42656091 -0.42602877 -0.42398574 -0.42076678 -0.4181405  -0.41860047\n",
      " -0.42329657 -0.42041351 -0.41617648 -0.41995526 -0.42172577 -0.41893952\n",
      " -0.41747842 -0.42054533 -0.4173619  -0.41667023 -0.41654274 -0.41680465\n",
      " -0.41718441 -0.41664451 -0.4157879  -0.41878771 -0.416488   -0.41675616]\n",
      "  warnings.warn(\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.16116337 -0.16165081 -0.16064277\n",
      " -0.23400481 -0.22950933 -0.22997892 -0.28012847 -0.28169234 -0.28158583\n",
      " -0.26988884 -0.26885897 -0.26919904 -0.27870015 -0.27801591 -0.27639443\n",
      " -0.30805051 -0.3096226  -0.30890963 -0.3250202  -0.32393067 -0.32489973\n",
      " -0.32282023 -0.32268083 -0.32480786 -0.3289154  -0.32842933 -0.32894908\n",
      " -0.16284511 -0.16236387 -0.16219993 -0.29328679 -0.29238297 -0.29277128\n",
      " -0.33501462 -0.33550084 -0.33526673 -0.32246278 -0.32302243 -0.322089\n",
      " -0.32812427 -0.32779406 -0.32760306 -0.34965198 -0.34802975 -0.34868844\n",
      " -0.36192103 -0.36125679 -0.3605272  -0.36067915 -0.36027854 -0.35985328\n",
      " -0.36359759 -0.36270359 -0.36299599         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.22250803 -0.22408942 -0.22698933 -0.26545644 -0.26260307 -0.26343279\n",
      " -0.2998936  -0.2982771  -0.29872585 -0.28650237 -0.28548743 -0.28706731\n",
      " -0.29359873 -0.291928   -0.28995219 -0.31720032 -0.31743034 -0.3167126\n",
      " -0.32883702 -0.32894104 -0.32823729 -0.32909633 -0.32809117 -0.32909776\n",
      " -0.33344448 -0.33322948 -0.33271945 -0.26143769 -0.26070696 -0.26074283\n",
      " -0.3172317  -0.31934222 -0.32022452 -0.34538127 -0.3467337  -0.34644216\n",
      " -0.33973724 -0.33724502 -0.33694126 -0.33997299 -0.34022832 -0.34079533\n",
      " -0.3550538  -0.35485579 -0.35533751 -0.36459073 -0.36452711 -0.36461896\n",
      " -0.36457826 -0.36466199 -0.36547184 -0.36787809 -0.36699314 -0.36693802\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.16439378 -0.16016479 -0.1610991\n",
      " -0.23170606 -0.23253805 -0.23225426 -0.28061123 -0.28037134 -0.28239981\n",
      " -0.26876681 -0.2702631  -0.26973463 -0.27779673 -0.27652501 -0.27674736\n",
      " -0.30696607 -0.30832796 -0.30933353 -0.32580345 -0.32532991 -0.32353573\n",
      " -0.32509386 -0.32425264 -0.32577907 -0.32797315 -0.33019242 -0.32987062\n",
      " -0.1650285  -0.16355954 -0.1657973  -0.29380012 -0.29196474 -0.29189099\n",
      " -0.33538447 -0.33574929 -0.33462945 -0.3216699  -0.3227647  -0.32355582\n",
      " -0.32582437 -0.32807742 -0.32748671 -0.34939593 -0.34771046 -0.348221\n",
      " -0.36090164 -0.36063408 -0.36087719 -0.36084987 -0.36037314 -0.36021463\n",
      " -0.36441946 -0.36282693 -0.36249252         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.15876065 -0.15914646 -0.1611561  -0.23351538 -0.23203032 -0.23061588\n",
      " -0.28394543 -0.28275133 -0.28042256 -0.2715885  -0.27058235 -0.27038634\n",
      " -0.27559633 -0.27640611 -0.27541332 -0.31017244 -0.30687848 -0.3091716\n",
      " -0.32491352 -0.32518789 -0.32433243 -0.32361999 -0.32426801 -0.3249565\n",
      " -0.33012528 -0.32997945 -0.32949064 -0.16379891 -0.16168081 -0.16230517\n",
      " -0.29234728 -0.29070953 -0.29148821 -0.33656706 -0.33423361 -0.33484144\n",
      " -0.32216338 -0.32275202 -0.32274952 -0.32752035 -0.32862339 -0.32703073\n",
      " -0.34900627 -0.34814772 -0.3475173  -0.36006847 -0.36054452 -0.36086176\n",
      " -0.35947398 -0.36034583 -0.36058792 -0.3640998  -0.36361594 -0.36301066]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n_estimators max_depth max_features  min_samples_split  min_samples_leaf  \\\n",
      "0             100      None         auto                  2                 1   \n",
      "1             200      None         auto                  2                 1   \n",
      "2             300      None         auto                  2                 1   \n",
      "3             100      None         auto                  5                 1   \n",
      "4             200      None         auto                  5                 1   \n",
      "..            ...       ...          ...                ...               ...   \n",
      "319           200        30         log2                  5                 4   \n",
      "320           300        30         log2                  5                 4   \n",
      "321           100        30         log2                 10                 4   \n",
      "322           200        30         log2                 10                 4   \n",
      "323           300        30         log2                 10                 4   \n",
      "\n",
      "     mean_test_score  std_test_score  \n",
      "0                NaN             NaN  \n",
      "1                NaN             NaN  \n",
      "2                NaN             NaN  \n",
      "3                NaN             NaN  \n",
      "4                NaN             NaN  \n",
      "..               ...             ...  \n",
      "319        -0.416645        0.121660  \n",
      "320        -0.415788        0.121697  \n",
      "321        -0.418788        0.122781  \n",
      "322        -0.416488        0.120426  \n",
      "323        -0.416756        0.121743  \n",
      "\n",
      "[324 rows x 7 columns]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:29:35.494159Z",
     "start_time": "2024-07-23T07:21:20.479040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_type = \"TotalPartsSold\"\n",
    "presence_type = \"binary\"\n",
    "vehicle_presence_df = DataframeBuilder.vehicle_presence(presence_type=presence_type, vehicle_type=\"year_model\",\n",
    "                                                        target_type=target_type)\n",
    "\n",
    "vehicle_presence_df.columns = vehicle_presence_df.columns.astype(str)\n",
    "# Create the machine learning model steps here, including training and testing LR\n",
    "# Separating features and target\n",
    "X = vehicle_presence_df.drop(columns=[target_type, 'Date'])\n",
    "y = vehicle_presence_df[target_type]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Lasso regression model\n",
    "random_forest = RandomForestRegressor()\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for tuning\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5,\n",
    "                           scoring='neg_mean_absolute_percentage_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame({\n",
    "    'n_estimators': results['param_n_estimators'],\n",
    "    'max_depth': results['param_max_depth'],\n",
    "    'max_features': results['param_max_features'],\n",
    "    'min_samples_split': results['param_min_samples_split'],\n",
    "    'min_samples_leaf': results['param_min_samples_leaf'],\n",
    "    'mean_test_score': results['mean_test_score'],\n",
    "    'std_test_score': results['std_test_score']\n",
    "})\n",
    "\n",
    "print(results_df)"
   ],
   "id": "682c339ecec35377",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.34143358 -0.34072645 -0.34010028\n",
      " -0.32864334 -0.32721254 -0.32735041 -0.31898466 -0.3182333  -0.31998637\n",
      " -0.32308476 -0.32401516 -0.32295322 -0.32309514 -0.32197584 -0.32274796\n",
      " -0.31738368 -0.31696317 -0.31758476 -0.31504626 -0.31446109 -0.3137255\n",
      " -0.31576646 -0.31485268 -0.31432112 -0.31562751 -0.31333785 -0.31359248\n",
      " -0.33747546 -0.34070341 -0.33801506 -0.32187837 -0.32114099 -0.32115348\n",
      " -0.31557198 -0.31464367 -0.31469472 -0.3143696  -0.31572516 -0.31675433\n",
      " -0.31570931 -0.31472648 -0.31544827 -0.31383794 -0.31366679 -0.31488218\n",
      " -0.31536284 -0.31505009 -0.31542597 -0.31580222 -0.31539415 -0.31481044\n",
      " -0.31569189 -0.31322259 -0.31474291         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.32964619 -0.33099884 -0.33143367 -0.32460174 -0.32446783 -0.32439959\n",
      " -0.31910272 -0.31881643 -0.31829377 -0.32217212 -0.32055877 -0.32225357\n",
      " -0.32035068 -0.32089336 -0.32068265 -0.31854415 -0.31643938 -0.31680027\n",
      " -0.31395888 -0.3137819  -0.3138398  -0.31425142 -0.31499395 -0.31420713\n",
      " -0.3152126  -0.31484865 -0.31404057 -0.32388091 -0.32620812 -0.32726062\n",
      " -0.3180529  -0.31663279 -0.31924221 -0.31431957 -0.31372507 -0.31380586\n",
      " -0.31744064 -0.31632511 -0.31558436 -0.31499124 -0.31392    -0.31571988\n",
      " -0.3139893  -0.31331861 -0.3134928  -0.31588873 -0.31553984 -0.31509728\n",
      " -0.31511011 -0.31569634 -0.31475016 -0.31682231 -0.31481333 -0.3155918\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.34036131 -0.33983041 -0.34025424\n",
      " -0.32653346 -0.32735401 -0.32909671 -0.31887094 -0.31888627 -0.31780502\n",
      " -0.32299222 -0.32337506 -0.32228785 -0.32189375 -0.32241715 -0.32246318\n",
      " -0.3167452  -0.31785725 -0.31680789 -0.31402053 -0.31514945 -0.31434106\n",
      " -0.31474466 -0.31458859 -0.31538635 -0.31522613 -0.31388755 -0.31442676\n",
      " -0.3387932  -0.33902008 -0.33981289 -0.32133229 -0.32130488 -0.32055475\n",
      " -0.31452708 -0.31445051 -0.31414685 -0.31642976 -0.31659903 -0.31720944\n",
      " -0.3152303  -0.31588957 -0.31596933 -0.31515073 -0.31260359 -0.3146907\n",
      " -0.31617083 -0.31468662 -0.31493293 -0.31548911 -0.31500624 -0.31382236\n",
      " -0.31541711 -0.31564566 -0.31507401         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.33735532 -0.34022657 -0.34002667 -0.32892939 -0.32626615 -0.32724399\n",
      " -0.31962607 -0.31865787 -0.31795497 -0.32518776 -0.32535176 -0.32364772\n",
      " -0.320384   -0.32161841 -0.3210501  -0.31631375 -0.31654546 -0.31603716\n",
      " -0.31468521 -0.3151771  -0.31486818 -0.3147318  -0.3151852  -0.31488286\n",
      " -0.31320954 -0.31473367 -0.31400749 -0.33831904 -0.34179913 -0.3378045\n",
      " -0.32052377 -0.32124217 -0.32011476 -0.31288664 -0.31356124 -0.31401461\n",
      " -0.31736046 -0.31710251 -0.31704415 -0.31566521 -0.31526122 -0.31486617\n",
      " -0.31432899 -0.3146303  -0.31385568 -0.31569122 -0.31472765 -0.31430389\n",
      " -0.31542772 -0.31467642 -0.31514339 -0.31560189 -0.31512277 -0.31502287]\n",
      "  warnings.warn(\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.12696925 -0.12523217 -0.12572751\n",
      " -0.2033053  -0.20448424 -0.20381736 -0.23759166 -0.23708171 -0.2375083\n",
      " -0.22367047 -0.22390564 -0.22366025 -0.2280563  -0.22882977 -0.22800236\n",
      " -0.24790209 -0.2486247  -0.24833736 -0.2590468  -0.25803114 -0.25774705\n",
      " -0.25908261 -0.25780502 -0.25786988 -0.26135408 -0.26089436 -0.2602527\n",
      " -0.12563888 -0.12613457 -0.12491337 -0.23508062 -0.23517202 -0.23510478\n",
      " -0.26631729 -0.26637807 -0.26665302 -0.25585342 -0.25607111 -0.25580335\n",
      " -0.25850245 -0.25881817 -0.25875052 -0.27302926 -0.27338682 -0.27381195\n",
      " -0.28318316 -0.2821273  -0.28320991 -0.28336988 -0.28274469 -0.28300954\n",
      " -0.28370811 -0.28433025 -0.28414482         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.17483086 -0.17304886 -0.1736699  -0.21873732 -0.21786592 -0.21753454\n",
      " -0.24253678 -0.24249852 -0.24328642 -0.23153117 -0.23114623 -0.23079583\n",
      " -0.23524067 -0.23505858 -0.23403315 -0.25109684 -0.25177565 -0.25198011\n",
      " -0.25948377 -0.25936799 -0.25914167 -0.26050642 -0.25982381 -0.25961375\n",
      " -0.2626362  -0.26188773 -0.26196228 -0.1978012  -0.19795314 -0.19754358\n",
      " -0.25134706 -0.2495959  -0.25029189 -0.2707086  -0.27181789 -0.27235592\n",
      " -0.26409348 -0.26394645 -0.26413175 -0.26700604 -0.26571055 -0.26627696\n",
      " -0.27732181 -0.27654838 -0.27708656 -0.28459132 -0.28487399 -0.28491603\n",
      " -0.28501975 -0.28491221 -0.2847438  -0.28723472 -0.28537824 -0.28570832\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.12463183 -0.1262044  -0.12693332\n",
      " -0.20328991 -0.20293509 -0.20379922 -0.23818333 -0.23744972 -0.23740336\n",
      " -0.22341242 -0.22510173 -0.22403675 -0.22844396 -0.22837799 -0.22751389\n",
      " -0.24916501 -0.2481321  -0.24837538 -0.25762828 -0.25798413 -0.25790037\n",
      " -0.25904109 -0.25856456 -0.25827235 -0.26150173 -0.26051384 -0.26071914\n",
      " -0.12763523 -0.12669408 -0.12503459 -0.23604222 -0.23544632 -0.2342677\n",
      " -0.26671782 -0.26560539 -0.26581809 -0.25617092 -0.25610514 -0.2563027\n",
      " -0.25920768 -0.2591809  -0.25950273 -0.27281678 -0.27301516 -0.27407975\n",
      " -0.28321646 -0.28305557 -0.28296739 -0.28349108 -0.2829507  -0.28244181\n",
      " -0.28446213 -0.28467079 -0.28427736         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.12684784 -0.12516944 -0.12601678 -0.20465694 -0.20385503 -0.20332337\n",
      " -0.23632731 -0.23804833 -0.23755139 -0.22351718 -0.22486711 -0.22348485\n",
      " -0.22826997 -0.22772025 -0.22719316 -0.2492609  -0.2487015  -0.24829116\n",
      " -0.2587561  -0.25898755 -0.25877022 -0.25715418 -0.25843764 -0.25818843\n",
      " -0.26078911 -0.26126404 -0.26060534 -0.12581609 -0.12662141 -0.12578571\n",
      " -0.23504737 -0.23409561 -0.23506883 -0.26711216 -0.26668422 -0.26628501\n",
      " -0.25616122 -0.25679962 -0.25659903 -0.25933375 -0.25928956 -0.25907298\n",
      " -0.2729381  -0.27339647 -0.27337682 -0.2836306  -0.28304943 -0.2830725\n",
      " -0.28263209 -0.28252136 -0.28243535 -0.28406891 -0.28424696 -0.28393352]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n_estimators max_depth max_features  min_samples_split  min_samples_leaf  \\\n",
      "0             100      None         auto                  2                 1   \n",
      "1             200      None         auto                  2                 1   \n",
      "2             300      None         auto                  2                 1   \n",
      "3             100      None         auto                  5                 1   \n",
      "4             200      None         auto                  5                 1   \n",
      "..            ...       ...          ...                ...               ...   \n",
      "319           200        30         log2                  5                 4   \n",
      "320           300        30         log2                  5                 4   \n",
      "321           100        30         log2                 10                 4   \n",
      "322           200        30         log2                 10                 4   \n",
      "323           300        30         log2                 10                 4   \n",
      "\n",
      "     mean_test_score  std_test_score  \n",
      "0                NaN             NaN  \n",
      "1                NaN             NaN  \n",
      "2                NaN             NaN  \n",
      "3                NaN             NaN  \n",
      "4                NaN             NaN  \n",
      "..               ...             ...  \n",
      "319        -0.314676        0.058983  \n",
      "320        -0.315143        0.060007  \n",
      "321        -0.315602        0.059769  \n",
      "322        -0.315123        0.059303  \n",
      "323        -0.315023        0.060055  \n",
      "\n",
      "[324 rows x 7 columns]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:38:49.058188Z",
     "start_time": "2024-07-23T07:29:35.496147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_type = \"TotalPartsSold\"\n",
    "presence_type = \"continuous\"\n",
    "vehicle_presence_df = DataframeBuilder.vehicle_presence(presence_type=presence_type, vehicle_type=\"year_model\",\n",
    "                                                        target_type=target_type)\n",
    "\n",
    "vehicle_presence_df.columns = vehicle_presence_df.columns.astype(str)\n",
    "# Create the machine learning model steps here, including training and testing LR\n",
    "# Separating features and target\n",
    "X = vehicle_presence_df.drop(columns=[target_type, 'Date'])\n",
    "y = vehicle_presence_df[target_type]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Lasso regression model\n",
    "random_forest = RandomForestRegressor()\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for tuning\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5,\n",
    "                           scoring='neg_mean_absolute_percentage_error', return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame({\n",
    "    'n_estimators': results['param_n_estimators'],\n",
    "    'max_depth': results['param_max_depth'],\n",
    "    'max_features': results['param_max_features'],\n",
    "    'min_samples_split': results['param_min_samples_split'],\n",
    "    'min_samples_leaf': results['param_min_samples_leaf'],\n",
    "    'mean_test_score': results['mean_test_score'],\n",
    "    'std_test_score': results['std_test_score']\n",
    "})\n",
    "\n",
    "print(results_df)"
   ],
   "id": "7f2655fd5f134b90",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "540 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.33268837 -0.33374214 -0.33334376\n",
      " -0.32726698 -0.32712789 -0.32849164 -0.32261346 -0.32195954 -0.3216323\n",
      " -0.32663365 -0.32712753 -0.32597799 -0.32684079 -0.32603717 -0.3246231\n",
      " -0.31987668 -0.32012589 -0.31936195 -0.31469387 -0.31604996 -0.31746811\n",
      " -0.31710272 -0.31612135 -0.3151411  -0.31685016 -0.31558476 -0.31477356\n",
      " -0.33441025 -0.33558839 -0.33636533 -0.32431186 -0.32200389 -0.32149252\n",
      " -0.3157774  -0.31470047 -0.31529139 -0.31904889 -0.31861218 -0.31854458\n",
      " -0.31828988 -0.31720274 -0.31801427 -0.31505277 -0.31377391 -0.31518686\n",
      " -0.31611367 -0.31466363 -0.31512963 -0.31542771 -0.31376697 -0.31496787\n",
      " -0.31690293 -0.31499997 -0.31565421         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.32839285 -0.32694607 -0.32792803 -0.32497878 -0.32292351 -0.32610486\n",
      " -0.31946431 -0.31967563 -0.31902105 -0.32365927 -0.32251512 -0.32324455\n",
      " -0.32424195 -0.32268045 -0.32291401 -0.31983623 -0.316846   -0.31860951\n",
      " -0.31681072 -0.31658424 -0.31612996 -0.31548937 -0.31544989 -0.31631538\n",
      " -0.31510327 -0.3152386  -0.31379852 -0.32561982 -0.32495348 -0.32316442\n",
      " -0.31863979 -0.3190951  -0.31892086 -0.31492889 -0.31477559 -0.31441581\n",
      " -0.31738069 -0.31685677 -0.31713938 -0.31844789 -0.31598321 -0.31627742\n",
      " -0.31572956 -0.31425392 -0.31451391 -0.31531747 -0.31521272 -0.31506904\n",
      " -0.31448659 -0.31497306 -0.31500517 -0.31474228 -0.31519591 -0.31473784\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.33325348 -0.33434965 -0.33197436\n",
      " -0.32797189 -0.3275096  -0.326837   -0.32023367 -0.32111983 -0.32033363\n",
      " -0.32742687 -0.32524837 -0.32561496 -0.32398481 -0.32472604 -0.32439107\n",
      " -0.31742987 -0.31962659 -0.31933662 -0.31642244 -0.31670271 -0.3158306\n",
      " -0.31553198 -0.31572024 -0.31587638 -0.31335958 -0.31621802 -0.31487875\n",
      " -0.33543005 -0.33453937 -0.33385619 -0.32041852 -0.3211326  -0.32061778\n",
      " -0.31701125 -0.3157192  -0.31653299 -0.31898246 -0.3186607  -0.31652341\n",
      " -0.31608587 -0.31804634 -0.31734147 -0.31712954 -0.31603933 -0.31342921\n",
      " -0.31377382 -0.3156115  -0.31463589 -0.3148467  -0.31587926 -0.31539503\n",
      " -0.31528222 -0.31373614 -0.31375446         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.33391106 -0.33348287 -0.33233733 -0.32964083 -0.32706144 -0.32740621\n",
      " -0.32053479 -0.32175419 -0.32115677 -0.32638201 -0.32538797 -0.32633321\n",
      " -0.32569275 -0.32400105 -0.32438634 -0.31679949 -0.32003892 -0.31889672\n",
      " -0.31584759 -0.31610012 -0.31657378 -0.31684463 -0.31700822 -0.31619469\n",
      " -0.31469365 -0.31591979 -0.31513254 -0.33836505 -0.33493978 -0.33578315\n",
      " -0.32370013 -0.3209497  -0.32138967 -0.31763572 -0.31656841 -0.31521605\n",
      " -0.3185235  -0.31806954 -0.31754489 -0.32079871 -0.31721483 -0.31824943\n",
      " -0.31518137 -0.31354132 -0.31473616 -0.31517442 -0.3155064  -0.31555075\n",
      " -0.3154462  -0.31322696 -0.31486129 -0.31489071 -0.31505645 -0.31448906]\n",
      "  warnings.warn(\n",
      "C:\\Users\\aljo9\\PycharmProjects\\NV_Picapart_Analysis\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.12524329 -0.12267973 -0.12347947\n",
      " -0.18208339 -0.18056234 -0.17970514 -0.21756384 -0.21873775 -0.21825598\n",
      " -0.20816217 -0.20753558 -0.20816681 -0.21355344 -0.21328553 -0.21356164\n",
      " -0.23829222 -0.23682661 -0.23751718 -0.24777937 -0.24830727 -0.24866148\n",
      " -0.24834672 -0.24910978 -0.2483731  -0.25107082 -0.25112183 -0.25131989\n",
      " -0.12358662 -0.1237378  -0.12405575 -0.22419364 -0.22348419 -0.22314107\n",
      " -0.25518361 -0.25498924 -0.25570623 -0.24725085 -0.24702839 -0.24736149\n",
      " -0.25151379 -0.25020912 -0.2504254  -0.26492542 -0.26626897 -0.26489744\n",
      " -0.27450778 -0.27499542 -0.27511843 -0.27467828 -0.27470698 -0.2752294\n",
      " -0.27772287 -0.27666253 -0.27673516         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.17109352 -0.17140463 -0.17015659 -0.20325688 -0.20154821 -0.20136096\n",
      " -0.22725673 -0.22789582 -0.22817764 -0.21895283 -0.21903518 -0.21730839\n",
      " -0.22210659 -0.22186879 -0.2222625  -0.24181664 -0.24109794 -0.24138198\n",
      " -0.25043496 -0.24964097 -0.25046563 -0.25018665 -0.24939947 -0.2504175\n",
      " -0.2535663  -0.2536883  -0.25308215 -0.19752322 -0.19489544 -0.19340459\n",
      " -0.24250357 -0.24074338 -0.24140213 -0.26252255 -0.262848   -0.2621208\n",
      " -0.25589397 -0.25600936 -0.2563413  -0.25826273 -0.25775616 -0.2584227\n",
      " -0.26986685 -0.27021103 -0.26911403 -0.27711519 -0.27768308 -0.27784429\n",
      " -0.27726494 -0.27784695 -0.2775292  -0.27846773 -0.2791316  -0.27929589\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.12454456 -0.12409515 -0.12416723\n",
      " -0.1815012  -0.18065497 -0.17964094 -0.21784575 -0.21762393 -0.21782489\n",
      " -0.20937485 -0.20843889 -0.20772836 -0.21289392 -0.212901   -0.21206433\n",
      " -0.23749655 -0.23707015 -0.23735238 -0.24774734 -0.24783318 -0.24735049\n",
      " -0.24853981 -0.24890793 -0.24783098 -0.2529859  -0.25207426 -0.25153333\n",
      " -0.12386136 -0.12607661 -0.1238968  -0.22524709 -0.22426392 -0.22402317\n",
      " -0.2569247  -0.25534109 -0.25615696 -0.24663797 -0.24697328 -0.24607691\n",
      " -0.24992606 -0.25031429 -0.25073282 -0.26569585 -0.26564916 -0.26484225\n",
      " -0.27449971 -0.27584279 -0.27490455 -0.27569052 -0.27523429 -0.27470376\n",
      " -0.2772572  -0.27655312 -0.27671265         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.1233286  -0.12458684 -0.12305715 -0.17921035 -0.17861222 -0.1807641\n",
      " -0.21824731 -0.21736318 -0.21803848 -0.20805316 -0.20864947 -0.20838579\n",
      " -0.21325735 -0.21252949 -0.21328047 -0.23774424 -0.23767213 -0.23704151\n",
      " -0.24842492 -0.24841506 -0.24872066 -0.24798076 -0.24757963 -0.24863076\n",
      " -0.25140451 -0.25140519 -0.25170642 -0.12554883 -0.124404   -0.12496199\n",
      " -0.22355618 -0.22351891 -0.22372704 -0.25523497 -0.25583182 -0.25575385\n",
      " -0.24726579 -0.24689493 -0.24657909 -0.25055632 -0.25014741 -0.24972954\n",
      " -0.2663805  -0.26555676 -0.2647995  -0.27548851 -0.27487891 -0.27546276\n",
      " -0.27551831 -0.27488865 -0.27560122 -0.27662902 -0.27634275 -0.27664057]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n_estimators max_depth max_features  min_samples_split  min_samples_leaf  \\\n",
      "0             100      None         auto                  2                 1   \n",
      "1             200      None         auto                  2                 1   \n",
      "2             300      None         auto                  2                 1   \n",
      "3             100      None         auto                  5                 1   \n",
      "4             200      None         auto                  5                 1   \n",
      "..            ...       ...          ...                ...               ...   \n",
      "319           200        30         log2                  5                 4   \n",
      "320           300        30         log2                  5                 4   \n",
      "321           100        30         log2                 10                 4   \n",
      "322           200        30         log2                 10                 4   \n",
      "323           300        30         log2                 10                 4   \n",
      "\n",
      "     mean_test_score  std_test_score  \n",
      "0                NaN             NaN  \n",
      "1                NaN             NaN  \n",
      "2                NaN             NaN  \n",
      "3                NaN             NaN  \n",
      "4                NaN             NaN  \n",
      "..               ...             ...  \n",
      "319        -0.313227        0.058439  \n",
      "320        -0.314861        0.058709  \n",
      "321        -0.314891        0.059398  \n",
      "322        -0.315056        0.058625  \n",
      "323        -0.314489        0.059471  \n",
      "\n",
      "[324 rows x 7 columns]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "import pandas as pd\n",
    "# Get the coefficients from the RF Model\n",
    "coef = random_forest.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importance = pd.DataFrame({'feature': X.columns, 'importance': coef})\n",
    "feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(feature_importance.head(10))"
   ],
   "id": "e3518f41b15bc20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T07:38:49.073204Z",
     "start_time": "2024-07-23T07:38:49.060195Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ae0cc763ea901726",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
